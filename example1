# Install the required libraries (uncomment these lines if not already installed)
!pip install transformers datasets

from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM

# Load a pre-trained model and tokenizer from Hugging Face Model Hub
model_name = "gpt2"  # You can change this to any other open-source model from Hugging Face (like 'EleutherAI/gpt-neo-1.3B')
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(model_name)

# Create a text generation pipeline
text_generator = pipeline("text-generation", model=model, tokenizer=tokenizer)

# Define the input prompt
prompt = "I have decided to shift my focus from paid LLMs to exploring the open-source landscape"

# Generate text
output = text_generator(prompt, max_length=100, num_return_sequences=1)

# Print the generated output
print(output[0]['generated_text'])
